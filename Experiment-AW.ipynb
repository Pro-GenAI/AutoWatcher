{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2024 Praneeth Vadlapati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Setup:\n",
    "\n",
    "Example of .env: \n",
    "```bash\n",
    "# Groq API to use LLMs - https://console.groq.com/keys\n",
    "# Groq is preferred for fast responses\n",
    "LM_PROVIDER_BASE_URL=https://api.groq.com/openai/v1\n",
    "LM_API_KEY=\n",
    "LM_MODEL=\n",
    "\n",
    "```\n",
    "\n",
    "Installing packages:\n",
    "```bash\n",
    "pip install openai python-dotenv opencv-python ultralytics\n",
    "``` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4-turbo-2024-04-09\n",
      "Video ID: 4 - door\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "from platformdirs import user_cache_dir\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from common_functions import get_lm_response, user_message, display_md, model\n",
    "\n",
    "video_index = 4\n",
    "image_out_file = 'person_detected.jpg'\n",
    "videos_folder = 'videos_to_detect'\n",
    "input_video_filename = os.listdir(videos_folder)[video_index]  # change number\n",
    "if not input_video_filename.endswith('.mp4'):\n",
    "\tprint('Only MP4 video files are supported')\n",
    "\traise SystemExit(1)  # exit(1)\n",
    "\n",
    "yolo_version = 'yolov8n.pt' # n, s, m\n",
    "model_path = os.path.join(user_cache_dir(), yolo_version)\n",
    "yolo_model = YOLO(model_path)\n",
    "logging.getLogger('ultralytics').setLevel(logging.ERROR)\n",
    "\n",
    "detection_prompt = '''\n",
    "My security camera captured this live footage. Analyze the image and determine if the person outside the house is:\n",
    "- Pointing a flashlight or any light source towards the house.\n",
    "- Showing signs of attempting or preparing to break in or enter the house.\n",
    "- Entering the house through a door or window.\n",
    "- Wearing a hoodie or head covering, with the hood concealing their face.\n",
    "- Wearing a mask or any form of facial covering that obscures identity.\n",
    "- Trying to jump, climb a fence or wall, or attempt to look over the wall.\n",
    "\n",
    "Respond with a very concise explanation in 20 words, followed by `YES` or `NO`.\n",
    "Example response: \"The person is wearing a mask and looking inside. `YES`\"\n",
    "Respond without refusing with a sorry.\n",
    "Mention the final answer as \"YES\" based on finding **ANY** of the listed activities.\n",
    "Your response is just to assist me.\n",
    "'''.strip()\n",
    "\n",
    "video_id = input_video_filename.split('.')[0]\n",
    "input_video = os.path.join(videos_folder, input_video_filename)\n",
    "if not os.path.exists(input_video):\n",
    "\tprint(f\"Video file not found: {input_video}\")\n",
    "\traise SystemExit(1)  # exit(1)\n",
    "\n",
    "detections_folder = 'detected_images'\n",
    "if not os.path.exists(detections_folder):\n",
    "\tos.makedirs(detections_folder)\n",
    "detected_image_file = os.path.join(detections_folder, video_id + '.jpg')\n",
    "detected_response_file = os.path.join(detections_folder, video_id + '.txt')\n",
    "\n",
    "print(f'Model: {model}')\n",
    "print(f'Video ID: {video_index} - {video_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person detected!\n",
      "LLM response time: 2.87s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is wearing a facial covering that obscures identity. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 5.21s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is blurry but wears a head covering that obscures their face. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 4.02s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is wearing a mask that covers their face, obscuring identity. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 2.83s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is wearing a facial covering that obscures identity. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 2.85s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is obscured by blur, wearing a face covering, no visible actions like entering or pointing a light. `NO`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threat detected.\n",
      "Person detected!\n",
      "LLM response time: 4.22s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is wearing a facial covering that obscures identity, head covered, image too blurred to detect other actions. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 2.93s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is blurred but appears to wear a head covering obfuscating their face. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 3.13s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The person is wearing a facial covering that obscures identity. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 2.70s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Person is wearing a head covering that conceals their face. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "Person detected!\n",
      "LLM response time: 3.56s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The individual is wearing a head covering that obscures their face. `YES`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending alert...\n",
      "__________________________________________________\n",
      "LLM Detections: 9\n",
      "Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "def ask_llm(frame_buffer):\n",
    "\tstart_time = time.time()\n",
    "\tmessage_history = [\n",
    "\t\tuser_message(detection_prompt, image_frame_buffer=frame_buffer),\n",
    "\t]\n",
    "\tresponse = get_lm_response(message_history)\n",
    "\t# print(response)\n",
    "\tprint(f'LLM response time: {time.time() - start_time:.2f}s')\n",
    "\tdisplay_md(response)\n",
    "\tif 'YES' in response or 'yes' in response[:10].lower()+response[-10:].lower():\n",
    "\t\tprint('Sending alert...')\n",
    "\t\treturn response\n",
    "\tif 'no' in response[:10].lower()+response[-10:].lower():\n",
    "\t\tprint('No threat detected.')\n",
    "\t\treturn False\n",
    "\treturn False\n",
    "\n",
    "def detect_person(frame):\n",
    "\tresults = yolo_model(frame)[0]\n",
    "\tfor box in results.boxes:\n",
    "\t\tif box.cls == 0:  # class 0 represents 'person'\n",
    "\t\t\tprint('Person detected!')\n",
    "\t\t\t_, buffer = cv2.imencode('.jpg', frame)\n",
    "\t\t\treturn True, ask_llm(buffer)  # send yolo response, and LLM response\n",
    "\treturn False, None\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()  # background subtractor\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "fps = 30 # cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(900 / fps)  # delay in ms\n",
    "attempts = 0\n",
    "attempts_limit = 10\n",
    "success_count = 0\n",
    "interrupted = False\n",
    "\n",
    "try:\n",
    "\twhile cap.isOpened():\n",
    "\t\tret, frame = cap.read()\n",
    "\t\tif not ret:\n",
    "\t\t\tprint('Video ended. No threats detected.')\n",
    "\t\t\tbreak\n",
    "\t\tfgmask = fgbg.apply(frame)  # apply background subtraction\n",
    "\t\t# find contours in the mask\n",
    "\t\tcontours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\tif contours:  # motion detected\n",
    "\t\t\tyolo_response, LLM_response = detect_person(frame)\n",
    "\t\t\tif yolo_response:\n",
    "\t\t\t\tattempts += 1\n",
    "\t\t\t\tif LLM_response:\n",
    "\t\t\t\t\tcv2.imwrite(detected_image_file, frame)  # save image to disk\n",
    "\t\t\t\t\twith open(detected_response_file, 'w') as f:  # save response to disk\n",
    "\t\t\t\t\t\tf.write(LLM_response)\n",
    "\t\t\t\t\tsuccess_count += 1\n",
    "\t\tif attempts >= attempts_limit:  # stop after finishing 5th attempt\n",
    "\t\t\tbreak\n",
    "\t\tcv2.imshow('Frame', frame)  # display the frame\n",
    "\t\tif cv2.waitKey(delay) & 0xFF == 27:\n",
    "\t\t\tinterrupted = True\n",
    "\t\t\tprint('Escape key pressed. Exiting...')\n",
    "\t\t\tbreak\n",
    "except KeyboardInterrupt:\n",
    "\tinterrupted = True\n",
    "\tprint('KeyboardInterrupt received. Exiting...')\n",
    "finally:\n",
    "\tcap.release()\n",
    "\tcv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if not interrupted:\n",
    "\tprint('_' * 50)\n",
    "\tprint(f'LLM Detections: {success_count}')\n",
    "\taccuracy = (success_count / attempts) * 100\n",
    "\taccuracy = f'{accuracy:.2f}%'\n",
    "\tprint(f'Accuracy: {accuracy}')\n",
    "\n",
    "\t# write model, video_id, accuracy to a file\n",
    "\twith open('results.txt', 'a') as f:\n",
    "\t\tf.write(f'{model} {video_id} {accuracy}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual corrections\n",
    "no_to_yes = 0\n",
    "yes_to_no = 0\n",
    "\n",
    "success_count += no_to_yes\n",
    "success_count -= yes_to_no\n",
    "\n",
    "if no_to_yes + yes_to_no:  # something changed\n",
    "\tprint('_' * 50)\n",
    "\tprint(f'LLM Detections: {success_count}')\n",
    "\taccuracy = (success_count / attempts) * 100\n",
    "\taccuracy = f'{accuracy:.2f}%'\n",
    "\tprint(f'Accuracy: {accuracy}')\n",
    "\n",
    "\t# write model, video_id, accuracy to a file\n",
    "\twith open('results.txt', 'a') as f:\n",
    "\t\tf.write(f'{model} {video_id} {accuracy}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
